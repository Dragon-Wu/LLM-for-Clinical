{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from http import HTTPStatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dashscope\n",
    "dashscope.api_key = \"sk-xxxxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'以下是关于医学知识的单项选择题，请根据题目输出唯一的答案选项\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = '''以下是关于医学知识的单项选择题，请根据题目输出唯一的答案选项\\n'''\n",
    "instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file_data = '../data/MedQA/Mainland/test.jsonl'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dict_test = []\n",
    "with open(path_file_data, 'r', encoding=\"utf-8\") as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        data = json.loads(line)\n",
    "        data['ID'] = idx\n",
    "        data['A'], data['B'], data['C'], data['D'], data['E'] = data['options']['A'], data['options']['B'], data['options']['C'], data['options']['D'], data['options']['E']\n",
    "        del data['options']\n",
    "        list_dict_test.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '经调查证实出现医院感染流行时，医院应报告当地卫生行政部门的时间是（\\u3000\\u3000）。',\n",
       " 'answer': '24小时内',\n",
       " 'meta_info': '卫生法规',\n",
       " 'answer_idx': 'E',\n",
       " 'ID': 0,\n",
       " 'A': '2小时',\n",
       " 'B': '4小时内',\n",
       " 'C': '8小时内',\n",
       " 'D': '12小时内',\n",
       " 'E': '24小时内'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dict_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3426/3426 [00:00<00:00, 685184.32it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx, dict_test in enumerate(tqdm(list_dict_test)):\n",
    "    question, answer = dict_test['question'], dict_test['answer']\n",
    "    a, b, c, d, e = dict_test['A'], dict_test['B'], dict_test['C'], dict_test['D'], dict_test['E']\n",
    "    question = question.replace(\"（ ）。\", \"\")\n",
    "    input = instruction + f\"问题：{question}: (A){a}, (B){b}, (C){c}, (D){d}, (E){e}\\n\" + \"答案：\"\n",
    "    dict_test['Input'] = input\n",
    "    # print(input, '\\t' ,answer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config of model\n",
    "model = \"qwen-72b-chat\"\n",
    "# qwen1.5-72b-chat, qwen1.5-14b-chat, qwen1.5-7b-chat\n",
    "# qwen-72b-chat, qwen-14b-chat, qwen-7b-chat\n",
    "# default config of model\n",
    "seed = 1234\n",
    "max_tokens = 1500\n",
    "# repetition_penalty  = 1.1\n",
    "result_format = 'text'\n",
    "# seted by user\n",
    "top_p = 0.0000001\n",
    "top_k = 0\n",
    "temperature = 0\n",
    "repetition_penalty  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(input, flag_print=True):\n",
    "    response = dashscope.Generation.call(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": input}\n",
    "        ],\n",
    "        result_format=result_format,\n",
    "        top_p=top_p,\n",
    "        top_k=top_k,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    if not response.status_code == HTTPStatus.OK:\n",
    "        print(\n",
    "            \"Request id: %s, Status code: %s, error code: %s, error message: %s\"\n",
    "            % (\n",
    "                response.request_id,\n",
    "                response.status_code,\n",
    "                response.code,\n",
    "                response.message,\n",
    "            )\n",
    "        )\n",
    "    if flag_print:\n",
    "        print(f'Response: {response[\"output\"][\"text\"]}', )\n",
    "        print(f\"Finish_reason: {response['output']['finish_reason']}\")\n",
    "        print(response['usage'])\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以下是关于医学知识的单项选择题，请根据题目输出唯一的答案选项\n",
      "问题：胃癌最主要的转移途径是（　　）。: (A)直接蔓延, (B)淋巴转移, (C)血行转移, (D)腹腔内种植, (E)盆腔转移\n",
      "答案：\n",
      "Response: (B)淋巴转移\n",
      "Finish_reason: stop\n",
      "{\"input_tokens\": 65, \"output_tokens\": 4, \"total_tokens\": 69}\n",
      "--------------------------------------------\n",
      "Ground-truth: 淋巴转移\n"
     ]
    }
   ],
   "source": [
    "idx = 6\n",
    "input = list_dict_test[idx]['Input']\n",
    "print(input)\n",
    "response = get_response(input)\n",
    "print('--------------------------------------------')\n",
    "print(f\"Ground-truth: {list_dict_test[idx]['answer']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_task = f\"QWEN72B-Prompt-{model}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../result/{name_task}.json', 'w', encoding=\"utf-8\") as f:\n",
    "    f.write(json.dumps(list_dict_test, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dict_test[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = 0\n",
    "list_failed = []\n",
    "for idx, dict_test in enumerate(tqdm(list_dict_test[start_idx:])):\n",
    "    idx = start_idx + idx\n",
    "    input = dict_test['Input']\n",
    "    try:\n",
    "        response = get_response(input, flag_print=False)\n",
    "        dict_test['Result'] = response['output']['text']\n",
    "        dict_test['finish_reason'] = response['output']['finish_reason']\n",
    "        dict_test['usage'] = response['usage']\n",
    "    except:\n",
    "        print(f\"Failed idx: {idx}\")\n",
    "        list_failed.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_failed_failed = []\n",
    "for idx_failed in tqdm(list_failed):\n",
    "    dict_test = list_dict_test[idx_failed]\n",
    "    input = dict_test['Input']\n",
    "    try:\n",
    "        response = get_response(input, flag_print=False)\n",
    "        dict_test['Result'] = response['output']['text']\n",
    "        dict_test['finish_reason'] = response['output']['finish_reason']\n",
    "        dict_test['usage'] = response['usage']\n",
    "    except:\n",
    "        print(f\"Failed idx: {idx_failed}\")\n",
    "        list_failed_failed.append(idx_failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx_failed in list_failed_failed:\n",
    "    list_dict_test[idx_failed]['Result'] = 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../result/{name_task}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(json.dumps(list_dict_test, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../result/{name_task}.json', 'r', encoding=\"utf-8\") as f:\n",
    "    list_dict_test = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dict_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_dict_test), len([dict_test for dict_test in list_dict_test if dict_test.get('usage')])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(result_pred, list_option_name):\n",
    "    list_str_split = ['最终答案是','最终答案为','最可能的选项是','最可能的诊断是','正确的选项是', '正确选项是', '正确选项为','最可能的答案是','最有可能的答案是']\n",
    "    for str_split in list_str_split:\n",
    "        if len(result_pred.split(str_split))>1:\n",
    "            result_pred = result_pred.split(str_split)[-1]\n",
    "            result_pred = result_pred.split('。')[0]\n",
    "            break\n",
    "    list_option_idx = [ chr(ord('A') + idx) for idx in range(len(list_option_name))]\n",
    "    list_option_idx_name = [ [option_idx, option_name] for option_idx, option_name in zip(list_option_idx, list_option_name)]\n",
    "    list_option_idx_name = sorted(list_option_idx_name, key=lambda x: len(x[1]), reverse=True)\n",
    "    list_option_match = []\n",
    "    # search option_idx and option_name\n",
    "    for option_idx, option_name in list_option_idx_name:\n",
    "        if option_idx in result_pred or option_name in result_pred:\n",
    "            list_option_match.append(option_idx)\n",
    "            if option_name in result_pred:\n",
    "                result_pred = result_pred.replace(option_name, '')\n",
    "    if len(list_option_match)==1:\n",
    "        return list_option_match[0]\n",
    "    elif len(list_option_match)>1:\n",
    "        return None\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dict_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dict_result_correct, list_dict_result_wrong, list_dict_result_none = [], [], []\n",
    "for idx, dict_test in enumerate(tqdm(list_dict_test)):\n",
    "    list_option_name = [dict_test['A'], dict_test['B'], dict_test['C'], dict_test['D'], dict_test['E']]\n",
    "    dict_test['prediction'] = get_prediction(dict_test['Result'], list_option_name)\n",
    "    if not dict_test['prediction']:\n",
    "        list_dict_result_none.append(dict_test)\n",
    "    elif dict_test['answer'] == dict_test['prediction']:\n",
    "        list_dict_result_correct.append(dict_test)\n",
    "    else:\n",
    "        list_dict_result_wrong.append(dict_test)\n",
    "    # if len(dict_test['Result']) > 6:\n",
    "    #     print(dict_test['Result']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_correct = len(list_dict_result_correct)\n",
    "count_wrong = len(list_dict_result_wrong)\n",
    "count_none = len(list_dict_result_none)\n",
    "acc = round(len(list_dict_result_correct) / len(list_dict_test)*100, 2)\n",
    "print(f\"Accuracy is {acc}% with {count_correct} correct, {count_wrong} wrong, and {count_none} none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Too long 111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../result/{name_task}.json', 'w', encoding=\"utf-8\") as f:\n",
    "    f.write(json.dumps(list_dict_test, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy for different types of questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../result/{name_task}-SAVE.json', 'r', encoding=\"utf-8\") as f:\n",
    "    list_dict_test_sample = json.load(f)\n",
    "with open('../data/list_test_knowledge_idx.txt', 'r') as f:\n",
    "    list_test_knowledge_idx = f.readlines()\n",
    "with open('../data/list_test_example_idx.txt', 'r') as f:\n",
    "    list_test_example_idx = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_test_knowledge_idx = [ int(idx.strip()) for idx in list_test_knowledge_idx if idx.strip() ]\n",
    "list_test_example_idx = [ int(idx.strip()) for idx in list_test_example_idx if idx.strip() ]\n",
    "list_dict_test_knowledge = [ list_dict_test_sample[idx] for idx in list_test_knowledge_idx ]\n",
    "list_dict_test_example = [ list_dict_test_sample[idx] for idx in list_test_example_idx ]\n",
    "print(len(list_dict_test_sample), len(list_dict_test_knowledge), len(list_dict_test_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_performance(list_dict_test_sample):\n",
    "    list_dict_result_correct, list_dict_result_wrong, list_dict_result_none = [], [], []\n",
    "    for idx, dict_test in enumerate(list_dict_test_sample):\n",
    "        if not dict_test['prediction']:\n",
    "            list_dict_result_none.append(dict_test)\n",
    "        elif dict_test['answer'] == dict_test['prediction']:\n",
    "            list_dict_result_correct.append(dict_test)\n",
    "        else:\n",
    "            list_dict_result_wrong.append(dict_test)\n",
    "    count_correct = len(list_dict_result_correct)\n",
    "    count_wrong = len(list_dict_result_wrong)\n",
    "    count_none = len(list_dict_result_none)\n",
    "    acc = len(list_dict_result_correct) / len(list_dict_test_sample)\n",
    "    print(f\"Accuracy is {round(acc*100, 2)}% with {count_none} none, {count_correct} correct, and {count_wrong} wrong， total {len(list_dict_test_sample)}\")\n",
    "    return round(acc, 4), count_none, count_correct, count_wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_MK, count_none_MK, _, _ = cal_performance(list_dict_test_knowledge)\n",
    "acc_CA, count_none_CA, _, _ = cal_performance(list_dict_test_example)\n",
    "acc_all, count_none_all, _, _ = cal_performance(list_dict_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_none_MK, acc_MK, count_none_CA, acc_CA, count_none_all, acc_all, sep='\\t')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0dda50c8f3106409627f3c7388c0a3de156665d66c9593dafc60667d2d1be47"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
