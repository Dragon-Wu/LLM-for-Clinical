{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import jieba\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from thefuzz import fuzz\n",
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\hp\\AppData\\Local\\Temp\\jieba.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.684 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "with open('../../data/THUOCL_medical.txt', 'r', encoding='utf-8') as f:\n",
    "    list_word_freq = f.readlines()\n",
    "list_word_freq = [ i.strip().split() for i in list_word_freq]\n",
    "list_word_freq = [ [word, int(freq)] for word, freq in list_word_freq]\n",
    "for (word, freq) in list_word_freq:\n",
    "    jieba.add_word(word.strip(),tag=freq)\n",
    "    jieba.suggest_freq(word, tune=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_idx(option, n_top, model):\n",
    "    tokenized_option = list(jieba.cut(option))\n",
    "    doc_scores = model.get_scores(tokenized_option)\n",
    "    list_sample_idx = np.argsort(doc_scores, axis=0)[-n_top:][::-1]\n",
    "    return list_sample_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_sample(option, n_top, model, list_sample):\n",
    "    tokenized_option = list(jieba.cut(option))\n",
    "    doc_scores = model.get_scores(tokenized_option)\n",
    "    list_sample_idx = np.argsort(doc_scores, axis=0)[-n_top:][::-1]\n",
    "    list_sample_similar = [list_sample[idx] for idx in list_sample_idx]\n",
    "    return list_sample_similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file_data = '../../data/MedQA/Mainland/test.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dict_test = []\n",
    "with open(path_file_data, 'r', encoding=\"utf-8\") as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        data = json.loads(line)\n",
    "        data['ID'] = idx\n",
    "        data['A'], data['B'], data['C'], data['D'], data['E'] = data['options']['A'], data['options']['B'], data['options']['C'], data['options']['D'], data['options']['E']\n",
    "        del data['options']\n",
    "        list_dict_test.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '经调查证实出现医院感染流行时，医院应报告当地卫生行政部门的时间是（\\u3000\\u3000）。',\n",
       " 'answer': '24小时内',\n",
       " 'meta_info': '卫生法规',\n",
       " 'answer_idx': 'E',\n",
       " 'ID': 0,\n",
       " 'A': '2小时',\n",
       " 'B': '4小时内',\n",
       " 'C': '8小时内',\n",
       " 'D': '12小时内',\n",
       " 'E': '24小时内'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dict_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Question Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_path_file_qb = ['../../data/MedQA/Mainland/train.jsonl', '../../data/MedQA/Mainland/dev.jsonl']\n",
    "# '../../data/MedQA/Mainland/chinese_qbank.jsonl', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 30825 samples\n"
     ]
    }
   ],
   "source": [
    "list_dict_sample_all = []\n",
    "for path_file_qb in list_path_file_qb:\n",
    "    with open(path_file_qb, 'r', encoding=\"utf-8\") as f:\n",
    "        for idx, line in enumerate(f):\n",
    "            data = json.loads(line)\n",
    "            data['ID'] = idx\n",
    "            data['A'], data['B'], data['C'], data['D'], data['E'] = data['options']['A'], data['options']['B'], data['options']['C'], data['options']['D'], data['options']['E']\n",
    "            del data['options']\n",
    "            list_dict_sample_all.append(data)\n",
    "print(f\"Loading {len(list_dict_sample_all)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '男，25岁，背部刀伤，伤口流血2h，体查：神志尚清楚，诉口渴，皮肤苍白，稍冷，脉搏110/min，血压12/9.33kPA（90/70mmHg），脉压小，表浅静脉塌陷，尿少。1．此病人休克达何种程度？（\\u3000\\u3000）',\n",
       " 'answer': '中度',\n",
       " 'meta_info': '第二部分\\u3000模拟试题',\n",
       " 'answer_idx': 'A',\n",
       " 'ID': 3424,\n",
       " 'A': '中度',\n",
       " 'B': '轻度',\n",
       " 'C': '重度',\n",
       " 'D': '晚期',\n",
       " 'E': '代偿期'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to remove the duplicate dict of list_sample_all and keep the order\n",
    "def remove_duplicate_dict(list_sample_all):\n",
    "    list_duplicate = []\n",
    "    list_sample_all_new = [list_sample_all[0]]\n",
    "    for dict_sample in tqdm(list_sample_all[1:]):\n",
    "        flag_in = False\n",
    "        str_option_sample =  dict_sample[\"A\"] + ' ' + dict_sample[\"B\"] + ' ' + dict_sample[\"C\"] + ' ' + dict_sample[\"D\"] + ' ' + dict_sample[\"E\"]\n",
    "        for dict_in in list_sample_all_new:\n",
    "            str_option_in =  dict_in[\"A\"] + ' ' + dict_in[\"B\"] + ' ' + dict_in[\"C\"] + ' ' + dict_in[\"D\"] + ' ' + dict_in[\"E\"]\n",
    "            if fuzz.ratio(dict_in['question'], dict_sample['question'])>50 and fuzz.ratio(str_option_sample, str_option_in)>65:\n",
    "                flag_in=True\n",
    "                list_duplicate.append([dict_in['question'], str_option_in, dict_sample['question'], str_option_sample])\n",
    "                break\n",
    "        if not flag_in:\n",
    "            list_sample_all_new.append(dict_sample)\n",
    "    return list_sample_all_new, list_duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of sample before removing duplicate: 30825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30824/30824 [10:23<00:00, 49.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of sample after removing duplicate: 30825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"The number of sample before removing duplicate: {len(list_dict_sample_all)}\")\n",
    "list_dict_sample_all, list_duplicate = remove_duplicate_dict(list_dict_sample_all)\n",
    "print(f\"The number of sample after removing duplicate: {len(list_dict_sample_all)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21382"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_dict_sample_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21382/21382 [00:00<00:00, 145715.44it/s]\n"
     ]
    }
   ],
   "source": [
    "list_dict_sample = []\n",
    "for idx, dict_sample_all in enumerate(tqdm(list_dict_sample_all)):\n",
    "    question, answer = dict_sample_all['question'], dict_sample_all['answer']\n",
    "    a, b, c, d, e = dict_sample_all['A'], dict_sample_all['B'], dict_sample_all['C'], dict_sample_all['D'], dict_sample_all['E']\n",
    "    question = re.sub(r'\\s*（\\s*）。*$', '', question)\n",
    "    question = re.sub(r'\\s*\\(\\s*\\)。*$', '', question)\n",
    "    dict_sample={'ID':dict_sample_all['ID'], 'question': question, 'A': a, 'B': b, 'C': c, 'D': d, 'E': e, 'answer': answer}\n",
    "    input = f\"问题：{question}: (A){a}, (B){b}, (C){c}, (D){d}, (E){e}\\n答案：{answer}\\n\"\n",
    "    dict_sample['Input'] = input\n",
    "    list_dict_sample.append(dict_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Bank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bm25_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We construct a Question Bank with 21382 questions\n"
     ]
    }
   ],
   "source": [
    "corpus_question = [ dict_one['question'] + ' ' + dict_one['A'] + ' ' + dict_one['B'] + ' ' + dict_one['C'] + ' ' + dict_one['D'] + ' ' + dict_one['E'] for dict_one in list_dict_sample ]\n",
    "tokenized_corpus_question = [ list(jieba.cut(doc)) for doc in corpus_question]\n",
    "bm25_question = BM25Okapi(tokenized_corpus_question)\n",
    "print(f'We construct a Question Bank with {len(corpus_question)} questions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1．Ⅰ期淋巴瘤（　　）。 病变仅限于一个解剖部位 病变累及右侧颈、腋下和腹股沟淋巴结 病变累及左腋下淋巴结及肝脏 病变累及右锁骨上淋巴结和左腋下，并伴有高热 病变累及左颈及纵隔淋巴结\n",
      "['1', '．', 'Ⅰ', '期', '淋巴瘤', '（', '\\u3000', '\\u3000', '）', '。', ' ', '病变', '仅限于', '一个', '解剖', '部位', ' ', '病变', '累及', '右侧', '颈', '、', '腋下', '和', '腹股沟淋巴结', ' ', '病变', '累及', '左', '腋下', '淋巴结', '及', '肝脏', ' ', '病变', '累及', '右', '锁骨上淋巴结', '和', '左', '腋下', '，', '并', '伴有', '高热', ' ', '病变', '累及', '左颈及', '纵隔', '淋巴结']\n"
     ]
    }
   ],
   "source": [
    "dict_test = list_dict_test[266]\n",
    "query = ( dict_test[\"question\"] + ' ' + dict_test[\"A\"] + ' ' + dict_test[\"B\"] + ' ' + dict_test[\"C\"] + ' ' + dict_test[\"D\"] + ' ' + dict_test[\"E\"]\n",
    ")\n",
    "print(query)\n",
    "tokenized_query = list(jieba.cut(query))\n",
    "print(tokenized_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296 3．Ⅲ期淋巴瘤 病变仅限于一个解剖部位 病变累及右侧颈、腋下和腹股沟淋巴结 病变累及左腋下淋巴结及肝 病变累及右锁骨上淋巴结和左腋下，并伴有高热 病变累及左颈及纵隔淋巴结\n",
      "9714 属于子宫内膜癌ⅡA期的是 病变侵犯肌层＞1/2 累及宫颈黏膜腺体 癌累及阴道上1/3段 病变侵犯浆膜和（或）附件 侵犯宫颈间质\n",
      "16680 女，22岁，左颈下及腋下出现无痛性肿块3月余，体检发现左侧颈部、锁骨上和腋窝等处，有肿大的孤立的无痛性肿大淋巴结，以下哪项发现最有助于提示此患者是霍奇金病，而非非霍奇金淋巴瘤？ 发病早期全身剧烈瘙痒 病变累及口咽和鼻咽部 硬膜外肿瘤压迫脊髓 伴发自身免疫性溶血性贫血 弥漫性组织细胞型淋巴瘤痛\n"
     ]
    }
   ],
   "source": [
    "doc_scores = bm25_question.get_scores(tokenized_query)\n",
    "for idx in np.argsort(doc_scores, axis=0)[-3:][::-1]:\n",
    "    print(idx, \"\".join(tokenized_corpus_question[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  296,  9714, 16680], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_sample_idx = get_similar_idx(query, n_top=3, model=bm25_question)\n",
    "list_sample_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ID': 297,\n",
       "  'question': '3．Ⅲ期淋巴瘤',\n",
       "  'A': '病变仅限于一个解剖部位',\n",
       "  'B': '病变累及右侧颈、腋下和腹股沟淋巴结',\n",
       "  'C': '病变累及左腋下淋巴结及肝',\n",
       "  'D': '病变累及右锁骨上淋巴结和左腋下，并伴有高热',\n",
       "  'E': '病变累及左颈及纵隔淋巴结',\n",
       "  'answer': '病变累及右侧颈、腋下和腹股沟淋巴结',\n",
       "  'Input': '问题：3．Ⅲ期淋巴瘤: (A)病变仅限于一个解剖部位, (B)病变累及右侧颈、腋下和腹股沟淋巴结, (C)病变累及左腋下淋巴结及肝, (D)病变累及右锁骨上淋巴结和左腋下，并伴有高热, (E)病变累及左颈及纵隔淋巴结\\n答案：病变累及右侧颈、腋下和腹股沟淋巴结\\n'},\n",
       " {'ID': 11388,\n",
       "  'question': '属于子宫内膜癌ⅡA期的是',\n",
       "  'A': '病变侵犯肌层＞1/2',\n",
       "  'B': '累及宫颈黏膜腺体',\n",
       "  'C': '癌累及阴道上1/3段',\n",
       "  'D': '病变侵犯浆膜和（或）附件',\n",
       "  'E': '侵犯宫颈间质',\n",
       "  'answer': '累及宫颈黏膜腺体',\n",
       "  'Input': '问题：属于子宫内膜癌ⅡA期的是: (A)病变侵犯肌层＞1/2, (B)累及宫颈黏膜腺体, (C)癌累及阴道上1/3段, (D)病变侵犯浆膜和（或）附件, (E)侵犯宫颈间质\\n答案：累及宫颈黏膜腺体\\n'},\n",
       " {'ID': 22110,\n",
       "  'question': '女，22岁，左颈下及腋下出现无痛性肿块3月余，体检发现左侧颈部、锁骨上和腋窝等处，有肿大的孤立的无痛性肿大淋巴结，以下哪项发现最有助于提示此患者是霍奇金病，而非非霍奇金淋巴瘤？',\n",
       "  'A': '发病早期全身剧烈瘙痒',\n",
       "  'B': '病变累及口咽和鼻咽部',\n",
       "  'C': '硬膜外肿瘤压迫脊髓',\n",
       "  'D': '伴发自身免疫性溶血性贫血',\n",
       "  'E': '弥漫性组织细胞型淋巴瘤痛',\n",
       "  'answer': '发病早期全身剧烈瘙痒',\n",
       "  'Input': '问题：女，22岁，左颈下及腋下出现无痛性肿块3月余，体检发现左侧颈部、锁骨上和腋窝等处，有肿大的孤立的无痛性肿大淋巴结，以下哪项发现最有助于提示此患者是霍奇金病，而非非霍奇金淋巴瘤？: (A)发病早期全身剧烈瘙痒, (B)病变累及口咽和鼻咽部, (C)硬膜外肿瘤压迫脊髓, (D)伴发自身免疫性溶血性贫血, (E)弥漫性组织细胞型淋巴瘤痛\\n答案：发病早期全身剧烈瘙痒\\n'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_similar_sample = get_similar_sample(query, n_top=3, model=bm25_question, list_sample=list_dict_sample)\n",
    "list_similar_sample"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_similar = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:12<00:00,  4.11it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx_testing, dict_test in enumerate(tqdm(list_dict_test[:50])):\n",
    "    question_and_options = dict_test[\"question\"] + ' ' + dict_test[\"A\"] + ' ' + dict_test[\"B\"] + ' ' + dict_test[\"C\"] + ' ' + dict_test[\"D\"] + ' ' + dict_test[\"E\"]\n",
    "    list_similar_sample = get_similar_sample(question_and_options, n_top=num_similar, model=bm25_question, list_sample=list_dict_sample)\n",
    "    dict_test['list_similar_sample'] = list_similar_sample"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'data_fewshot_enhancement.json', 'w', encoding=\"utf-8\") as f:\n",
    "    f.write(json.dumps(list_dict_test, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_similar = 10\n",
    "num_sample = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'data_fewshot_enhancement.json', 'r') as f:\n",
    "    list_dict_test_sample = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
