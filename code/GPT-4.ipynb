{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = 'sk-xxxxxx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'以下是关于医学知识的单项选择题，请根据题目输出唯一的答案选项\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = '''以下是关于医学知识的单项选择题，请根据题目输出唯一的答案选项\\n'''\n",
    "instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file_data = '../data/MedQA/Mainland/test.jsonl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dict_test = []\n",
    "with open(path_file_data, 'r', encoding=\"utf-8\") as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        data = json.loads(line)\n",
    "        data['ID'] = idx\n",
    "        data['A'], data['B'], data['C'], data['D'], data['E'] = data['options']['A'], data['options']['B'], data['options']['C'], data['options']['D'], data['options']['E']\n",
    "        del data['options']\n",
    "        list_dict_test.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '经调查证实出现医院感染流行时，医院应报告当地卫生行政部门的时间是（\\u3000\\u3000）。',\n",
       " 'answer': '24小时内',\n",
       " 'meta_info': '卫生法规',\n",
       " 'answer_idx': 'E',\n",
       " 'ID': 0,\n",
       " 'A': '2小时',\n",
       " 'B': '4小时内',\n",
       " 'C': '8小时内',\n",
       " 'D': '12小时内',\n",
       " 'E': '24小时内'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dict_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3426/3426 [00:00<00:00, 418843.58it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx, dict_test in enumerate(tqdm(list_dict_test)):\n",
    "    question, answer = dict_test['question'], dict_test['answer']\n",
    "    a, b, c, d, e = dict_test['A'], dict_test['B'], dict_test['C'], dict_test['D'], dict_test['E']\n",
    "    question = question.replace(\"（ ）。\", \"\")\n",
    "    input = instruction + f\"问题：{question}: (A){a}, (B){b}, (C){c}, (D){d}, (E){e}\\n\" + \"答案：\"\n",
    "    dict_test['Input'] = input\n",
    "    # print(input, '\\t' ,answer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config of model\n",
    "model = \"gpt-4-0613\"\n",
    "cost_input_1k = 0.03\n",
    "cost_output_1k = 0.06\n",
    "# \"gpt-3.5-turbo-0613\"\n",
    "# cost_input_1k = 0.0015\n",
    "# cost_output_1k = 0.002\n",
    "# 'gpt-3.5-0613'\n",
    "temperature = 0\n",
    "top_p = 1\n",
    "frequency_penalty = 0\n",
    "presence_penalty = 0\n",
    "prompt_system = \"\"\"You are ChatGPT, a large language model trained by OpenAI.\n",
    "Knowledge cutoff: max_thread21-09\n",
    "Current date: max_thread23-07-01\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_idx(input):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model, \n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        presence_penalty=presence_penalty,\n",
    "        # max_tokens = 1,\n",
    "        messages=[\n",
    "            # {\"role\": \"system\", \"content\": prompt_system}, \n",
    "            {\"role\": \"user\", \"content\": input}\n",
    "        ],\n",
    "        timeout=60,\n",
    "    )\n",
    "    print(f'Response: {response[\"choices\"][0][\"message\"][\"content\"]}', )\n",
    "    print(f\"Finish_reason: {response['choices'][0]['finish_reason']}\")\n",
    "    print(response['usage']._previous)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以下是关于医学知识的单项选择题，请根据题目输出唯一的答案选项\n",
      "问题：下述有关主动脉粥样硬化的叙述中，哪一项错误？（　　）: (A)病变多位于主动脉后壁和各分支开口处, (B)可引起夹层动脉瘤, (C)可引起主动脉瓣病变, (D)胸主动脉病变最重, (E)可继发溃疡、钙化、出血、血栓形成\n",
      "答案：\n",
      "Response: (D)胸主动脉病变最重\n",
      "Finish_reason: stop\n",
      "{'prompt_tokens': 186, 'completion_tokens': 15, 'total_tokens': 201}\n",
      "Ground-truth: 胸主动脉病变最重\n"
     ]
    }
   ],
   "source": [
    "idx = 99\n",
    "input = list_dict_test[idx]['Input']\n",
    "print(input)\n",
    "response = get_response_idx(input)\n",
    "print(f\"Ground-truth: {list_dict_test[idx]['answer']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_task = \"Prompt-gpt4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../result/{name_task}.json', 'w', encoding=\"utf-8\") as f:\n",
    "    f.write(json.dumps(list_dict_test, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dict_test[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python API_multithread.py \"{openai.api_key}\" \"{name_task}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../result/{name_task}.json', 'r', encoding=\"utf-8\") as f:\n",
    "    list_dict_test = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_dict_test), len([dict_test for dict_test in list_dict_test if dict_test.get('usage')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dict_test[50]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supplement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_failed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dict_result_failed = [ dict_test for dict_test in list_dict_test if not dict_test.get('usage') ]\n",
    "len(list_dict_result_failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag_failed:\n",
    "    for dict_test in tqdm(list_dict_result_failed):\n",
    "        input = dict_test[\"Input\"]\n",
    "        id = dict_test[\"ID\"]\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=model,\n",
    "                temperature=temperature,\n",
    "                top_p=top_p,\n",
    "                frequency_penalty=frequency_penalty,\n",
    "                presence_penalty=presence_penalty,\n",
    "                # max_tokens = 1,\n",
    "                messages=[\n",
    "                    # {\"role\": \"system\", \"content\": prompt_system},\n",
    "                    {\"role\": \"user\", \"content\": input},\n",
    "                ],\n",
    "                timeout=60,\n",
    "            )\n",
    "            result = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "            dict_test[\"Result\"] = result\n",
    "            # usage\n",
    "            dict_test[\"usage\"] = response[\"usage\"]._previous\n",
    "            # finish reason\n",
    "            dict_test[\"finish_reason\"] = response[\"choices\"][0][\"finish_reason\"]\n",
    "            # print(input, result, sep='\\n')\n",
    "        except:\n",
    "            print(f\"Wrong: {id}\\n\")\n",
    "    print('Supplement failed done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../result/{name_task}.json', 'w', encoding=\"utf-8\") as f:\n",
    "    f.write(json.dumps(list_dict_test, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(result_pred, list_option_name):\n",
    "    list_str_split = ['最终答案是','最终答案为','最可能的选项是','最可能的诊断是','正确的选项是', '正确选项是', '正确选项为','最可能的答案是','最有可能的答案是']\n",
    "    for str_split in list_str_split:\n",
    "        if len(result_pred.split(str_split))>1:\n",
    "            result_pred = result_pred.split(str_split)[-1]\n",
    "            result_pred = result_pred.split('。')[0]\n",
    "            break\n",
    "    list_option_idx = [ chr(ord('A') + idx) for idx in range(len(list_option_name))]\n",
    "    list_option_idx_name = [ [option_idx, option_name] for option_idx, option_name in zip(list_option_idx, list_option_name)]\n",
    "    list_option_idx_name = sorted(list_option_idx_name, key=lambda x: len(x[1]), reverse=True)\n",
    "    list_option_match = []\n",
    "    # search option_idx and option_name\n",
    "    for option_idx, option_name in list_option_idx_name:\n",
    "        if option_idx in result_pred or option_name in result_pred:\n",
    "            list_option_match.append(option_idx)\n",
    "            if option_name in result_pred:\n",
    "                result_pred = result_pred.replace(option_name, '')\n",
    "    if len(list_option_match)==1:\n",
    "        return list_option_match[0]\n",
    "    elif len(list_option_match)>1:\n",
    "        return None\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dict_result_correct, list_dict_result_wrong, list_dict_result_none = [], [], []\n",
    "for idx, dict_test in enumerate(tqdm(list_dict_test)):\n",
    "    list_option_name = [dict_test['A'], dict_test['B'], dict_test['C'], dict_test['D'], dict_test['E']]\n",
    "    dict_test['Prediction'] = get_prediction(dict_test['Result'], list_option_name)\n",
    "    if not dict_test['Prediction']:\n",
    "        list_dict_result_none.append(dict_test)\n",
    "    elif dict_test['answer'] == dict_test['Prediction']:\n",
    "        list_dict_result_correct.append(dict_test)\n",
    "    else:\n",
    "        list_dict_result_wrong.append(dict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_correct = len(list_dict_result_correct)\n",
    "count_wrong = len(list_dict_result_wrong)\n",
    "count_none = len(list_dict_result_none)\n",
    "acc = round(len(list_dict_result_correct) / len(list_dict_test)*100, 2)\n",
    "print(f\"Accuracy is {acc}% with {count_correct} correct, {count_wrong} wrong, and {count_none} none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../result/{name_task}.json', 'w', encoding=\"utf-8\") as f:\n",
    "    f.write(json.dumps(list_dict_test, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy for different types of questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../result/{name_task}.json', 'r', encoding=\"utf-8\") as f:\n",
    "    list_dict_test_sample = json.load(f)\n",
    "with open('../data/list_test_knowledge_idx.txt', 'r') as f:\n",
    "    list_test_knowledge_idx = f.readlines()\n",
    "with open('../data/list_test_example_idx.txt', 'r') as f:\n",
    "    list_test_example_idx = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_test_knowledge_idx = [ int(idx.strip()) for idx in list_test_knowledge_idx if idx.strip() ]\n",
    "list_test_example_idx = [ int(idx.strip()) for idx in list_test_example_idx if idx.strip() ]\n",
    "list_dict_test_knowledge = [ list_dict_test_sample[idx] for idx in list_test_knowledge_idx ]\n",
    "list_dict_test_example = [ list_dict_test_sample[idx] for idx in list_test_example_idx ]\n",
    "print(len(list_dict_test_sample), len(list_dict_test_knowledge), len(list_dict_test_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_performance(list_dict_test_sample):\n",
    "    list_dict_result_correct, list_dict_result_wrong, list_dict_result_none = [], [], []\n",
    "    for idx, dict_test in enumerate(list_dict_test_sample):\n",
    "        if not dict_test['Prediction']:\n",
    "            list_dict_result_none.append(dict_test)\n",
    "        elif dict_test['answer'] == dict_test['Prediction']:\n",
    "            list_dict_result_correct.append(dict_test)\n",
    "        else:\n",
    "            list_dict_result_wrong.append(dict_test)\n",
    "    count_correct = len(list_dict_result_correct)\n",
    "    count_wrong = len(list_dict_result_wrong)\n",
    "    count_none = len(list_dict_result_none)\n",
    "    acc = len(list_dict_result_correct) / len(list_dict_test_sample)\n",
    "    print(f\"Accuracy is {round(acc*100, 2)}% with {count_none} none, {count_correct} correct, and {count_wrong} wrong， total {len(list_dict_test_sample)}\")\n",
    "    return round(acc, 4), count_none, count_correct, count_wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_MK, count_none_MK, _, _ = cal_performance(list_dict_test_knowledge)\n",
    "acc_CA, count_none_CA, _, _ = cal_performance(list_dict_test_example)\n",
    "acc_all, count_none_all, _, _ = cal_performance(list_dict_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_none_MK, acc_MK, count_none_CA, acc_CA, count_none_all, acc_all, sep='\\t')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_cost(token_input, token_output, cost_input_1k, cost_output_1k):\n",
    "    cost_input = token_input * cost_input_1k / 1000 * 7.24\n",
    "    cost_output = token_output * cost_output_1k / 1000 * 7.24\n",
    "    print(f\"cost_input: {cost_input:.2f} rmb\")\n",
    "    print(f\"cost_output: {cost_output:.2f} rmb\")\n",
    "    print(f\"All cost: {(cost_input+cost_output):.2f} rmb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_input = sum([dict_test[\"usage\"][\"prompt_tokens\"] for dict_test in list_dict_test_sample])\n",
    "token_output = sum(\n",
    "    [dict_test[\"usage\"][\"completion_tokens\"] for dict_test in list_dict_test_sample]\n",
    ")\n",
    "cal_cost(token_input, token_output, cost_input_1k, cost_output_1k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0dda50c8f3106409627f3c7388c0a3de156665d66c9593dafc60667d2d1be47"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
