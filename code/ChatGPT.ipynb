{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import time\n",
    "import jieba\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from thefuzz import fuzz\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = 'sk-xxxxx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'以下是关于医学知识的单项选择题，请根据题目输出唯一的答案选项\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = '''以下是关于医学知识的单项选择题，请根据题目输出唯一的答案选项\\n'''\n",
    "instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/list_dict_test_2022.json', 'r', encoding=\"utf-8\") as f:\n",
    "    list_dict_test = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 494/494 [00:00<00:00, 493447.53it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx, dict_test in enumerate(tqdm(list_dict_test)):\n",
    "    question, answer = dict_test['Question'], dict_test['Answer']\n",
    "    a, b, c, d, e = dict_test['A'], dict_test['B'], dict_test['C'], dict_test['D'], dict_test['E']\n",
    "    question = question.replace(\"（ ）。\", \"\")\n",
    "    input = instruction + f\"问题：{question}: (A){a}, (B){b}, (C){c}, (D){d}, (E){e}\\n\" + \"答案：\"\n",
    "    dict_test['Input'] = input\n",
    "    # print(input, '\\t' ,answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_dict(dict_test):\n",
    "    input = dict_test['Input']\n",
    "    # print(input)\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\", \n",
    "        temperature=0,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        # max_tokens = 1,\n",
    "        messages=[\n",
    "            # {\"role\": \"system\", \"content\": instruction_system}, \n",
    "            {\"role\": \"user\", \"content\": input}\n",
    "        ],\n",
    "    )\n",
    "    print(f'Response: {response[\"choices\"][0][\"message\"][\"content\"]}\\n', )\n",
    "    print(f\"True Label: {dict_test['Answer']}\\n\")\n",
    "    print(f\"Finish_reason: {response['choices'][0]['finish_reason']}\\n\")\n",
    "    print(response['usage']._previous)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以下是关于医学知识的单项选择题，请根据题目输出唯一的答案选项\n",
      "问题：关于低位肠梗阻正确的是: (A)呕吐症状出现早, (B)梗阻部位多为空肠, (C)腹部X线可见多个阶梯状气液平, (D)腹痛腹胀不明显, (E)呕吐物多为胃内容物\n",
      "答案：\n"
     ]
    }
   ],
   "source": [
    "idx = 255\n",
    "dict_test = list_dict_test[idx]\n",
    "print(dict_test['Input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: C\n",
      "\n",
      "True Label: C\n",
      "\n",
      "Finish_reason: stop\n",
      "\n",
      "{'prompt_tokens': 154, 'completion_tokens': 1, 'total_tokens': 155}\n"
     ]
    }
   ],
   "source": [
    "response = get_response_dict(dict_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_task = \"Prompt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../input/{name_task}.json', 'w', encoding=\"utf-8\") as f:\n",
    "    f.write(json.dumps(list_dict_test, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_task:Prompt"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/494 [00:00<?, ?it/s]\n",
      "  0%|          | 1/494 [00:13<1:51:28, 13.57s/it]\n",
      "  4%|▎         | 18/494 [00:13<04:22,  1.82it/s] \n",
      "  5%|▌         | 25/494 [00:14<03:03,  2.56it/s]\n",
      "  6%|▌         | 29/494 [00:15<02:37,  2.95it/s]\n",
      "  7%|▋         | 34/494 [00:16<02:12,  3.47it/s]\n",
      "  7%|▋         | 36/494 [00:16<01:56,  3.92it/s]\n",
      "  8%|▊         | 38/494 [00:16<01:43,  4.40it/s]\n",
      "  9%|▉         | 44/494 [00:16<01:04,  6.96it/s]\n",
      " 10%|▉         | 48/494 [00:16<00:52,  8.46it/s]\n",
      " 11%|█         | 52/494 [00:16<00:40, 10.89it/s]\n",
      " 11%|█         | 55/494 [00:16<00:36, 12.14it/s]\n",
      " 12%|█▏        | 58/494 [00:17<00:45,  9.55it/s]\n",
      " 13%|█▎        | 62/494 [00:17<00:34, 12.51it/s]\n",
      " 13%|█▎        | 66/494 [00:17<00:30, 14.10it/s]\n",
      " 15%|█▍        | 72/494 [00:18<00:28, 14.76it/s]\n",
      " 16%|█▌        | 78/494 [00:18<00:20, 19.99it/s]\n",
      " 17%|█▋        | 82/494 [00:18<00:19, 21.17it/s]\n",
      " 17%|█▋        | 86/494 [00:18<00:18, 22.66it/s]\n",
      " 18%|█▊        | 89/494 [00:18<00:19, 20.32it/s]\n",
      " 19%|█▊        | 92/494 [00:18<00:19, 21.11it/s]\n",
      " 19%|█▉        | 96/494 [00:19<00:16, 23.43it/s]\n",
      " 21%|██        | 104/494 [00:19<00:15, 24.48it/s]\n",
      " 22%|██▏       | 108/494 [00:19<00:14, 26.89it/s]\n",
      " 23%|██▎       | 114/494 [00:19<00:11, 32.36it/s]\n",
      " 24%|██▍       | 118/494 [00:19<00:15, 24.13it/s]\n",
      " 26%|██▌       | 126/494 [00:20<00:12, 29.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ready for 494 data\n",
      "\n",
      "Wrong: 147\n",
      "\n",
      "Wrong: 448\n",
      "\n",
      "messages length:494, num_threads:64, time cost:339.1046471595764\n",
      "\n",
      "Supplement 2 failed\n",
      "\n",
      "Get response:494\n",
      "Cost: 1.32 RMB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 130/494 [00:20<00:11, 30.51it/s]\n",
      " 27%|██▋       | 134/494 [00:20<00:13, 26.91it/s]\n",
      " 30%|██▉       | 146/494 [00:20<00:07, 44.62it/s]\n",
      " 31%|███       | 152/494 [00:20<00:07, 44.31it/s]\n",
      " 33%|███▎      | 164/494 [00:20<00:07, 47.11it/s]\n",
      " 34%|███▍      | 170/494 [00:21<00:07, 44.55it/s]\n",
      " 36%|███▌      | 178/494 [00:21<00:06, 48.08it/s]\n",
      " 37%|███▋      | 184/494 [00:21<00:08, 34.85it/s]\n",
      " 38%|███▊      | 189/494 [00:21<00:08, 37.44it/s]\n",
      " 39%|███▉      | 194/494 [00:21<00:08, 33.48it/s]\n",
      " 43%|████▎     | 212/494 [00:21<00:04, 60.67it/s]\n",
      " 45%|████▍     | 220/494 [00:22<00:04, 58.96it/s]\n",
      " 47%|████▋     | 230/494 [00:22<00:04, 61.86it/s]\n",
      " 49%|████▊     | 240/494 [00:22<00:03, 67.47it/s]\n",
      " 50%|█████     | 248/494 [00:22<00:03, 69.78it/s]\n",
      " 52%|█████▏    | 256/494 [00:22<00:04, 47.88it/s]\n",
      " 53%|█████▎    | 263/494 [00:22<00:04, 50.32it/s]\n",
      " 55%|█████▌    | 274/494 [00:22<00:04, 54.74it/s]\n",
      " 57%|█████▋    | 281/494 [00:23<00:04, 52.99it/s]\n",
      " 59%|█████▊    | 290/494 [00:23<00:04, 48.31it/s]\n",
      " 61%|██████    | 302/494 [00:23<00:03, 56.16it/s]\n",
      " 63%|██████▎   | 312/494 [00:23<00:03, 58.67it/s]\n",
      " 65%|██████▌   | 322/494 [00:23<00:02, 66.64it/s]\n",
      " 67%|██████▋   | 330/494 [00:23<00:02, 67.11it/s]\n",
      " 69%|██████▉   | 340/494 [00:24<00:02, 69.46it/s]\n",
      " 72%|███████▏  | 358/494 [00:24<00:01, 91.79it/s]\n",
      " 75%|███████▍  | 370/494 [00:24<00:01, 84.42it/s]\n",
      " 77%|███████▋  | 380/494 [00:24<00:01, 77.87it/s]\n",
      " 79%|███████▉  | 390/494 [00:24<00:01, 75.98it/s]\n",
      " 81%|████████  | 400/494 [00:24<00:01, 78.57it/s]\n",
      " 83%|████████▎ | 409/494 [00:24<00:01, 79.87it/s]\n",
      " 85%|████████▍ | 418/494 [00:24<00:01, 71.92it/s]\n",
      " 86%|████████▌ | 426/494 [00:25<00:01, 53.73it/s]\n",
      " 88%|████████▊ | 434/494 [00:25<00:01, 58.07it/s]\n",
      " 92%|█████████▏| 454/494 [00:25<00:00, 82.85it/s]\n",
      " 94%|█████████▍| 464/494 [00:25<00:00, 82.09it/s]\n",
      " 96%|█████████▌| 474/494 [00:25<00:00, 86.17it/s]\n",
      " 98%|█████████▊| 484/494 [00:25<00:00, 73.86it/s]\n",
      "100%|██████████| 494/494 [00:25<00:00, 19.02it/s]\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      " 50%|█████     | 1/2 [00:00<00:00,  1.07it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.33it/s]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.28it/s]\n"
     ]
    }
   ],
   "source": [
    "!python turbo_json.py Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../log/{name_task}_0_494.json', 'r', encoding=\"utf-8\") as f:\n",
    "    list_dict_test = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(494, 494)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_dict_test), len([dict_test for dict_test in list_dict_test if dict_test.get('usage')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supplement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# # list_dict_result_failed = [ dict_test for dict_test in list_dict_test if not dict_test.get('usage') ]\n",
    "# list_dict_result_failed = [list_dict_test[5]]\n",
    "# print(f\"{len(list_dict_result_failed)} failed\")\n",
    "# for dict_test in list_dict_result_failed:\n",
    "#     input = dict_test['Input']\n",
    "#     id = dict_test['ID']\n",
    "#     response = openai.ChatCompletion.create(\n",
    "#             model=\"gpt-3.5-turbo\", \n",
    "#             temperature=0,\n",
    "#             n=1, \n",
    "#             top_p=1,\n",
    "#             frequency_penalty=0,\n",
    "#             presence_penalty=0,\n",
    "#             messages=[\n",
    "#                 # {\"role\": \"system\", \"content\": 'instruction for system'}, \n",
    "#                 {\"role\": \"user\", \"content\": input}]\n",
    "#     )\n",
    "#     result = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "#     dict_test['Result'] = result\n",
    "#     # usage\n",
    "#     dict_test['usage'] = response['usage']._previous\n",
    "#     # save_log(dict_test)\n",
    "#     print(input, result, sep='\\n')\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID': 255,\n",
       " 'Question': '关于低位肠梗阻正确的是',\n",
       " 'A': '呕吐症状出现早',\n",
       " 'B': '梗阻部位多为空肠',\n",
       " 'C': '腹部X线可见多个阶梯状气液平',\n",
       " 'D': '腹痛腹胀不明显',\n",
       " 'E': '呕吐物多为胃内容物',\n",
       " 'Answer': 'C',\n",
       " 'Analysis': '低位肠梗阻，扩张的肠袢在腹中部，腹部X线呈“阶梯状”排列，可见多个气液平。',\n",
       " 'Input': '以下是关于医学知识的单项选择题，请根据题目输出唯一的答案选项\\n问题：关于低位肠梗阻正确的是: (A)呕吐症状出现早, (B)梗阻部位多为空肠, (C)腹部X线可见多个阶梯状气液平, (D)腹痛腹胀不明显, (E)呕吐物多为胃内容物\\n答案：'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'log/{name_task}_0_494.json', 'w', encoding=\"utf-8\") as f:\n",
    "#     f.write(json.dumps(list_dict_test, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(result_pred, list_option_name):\n",
    "    list_str_split = ['最终答案是','最终答案为','最可能的选项是','最可能的诊断是','正确的选项是', '正确选项是', '正确选项为','最可能的答案是','最有可能的答案是']\n",
    "    for str_split in list_str_split:\n",
    "        if len(result_pred.split(str_split))>1:\n",
    "            result_pred = result_pred.split(str_split)[-1]\n",
    "            result_pred = result_pred.split('。')[0]\n",
    "            break\n",
    "    list_option_idx = [ chr(ord('A') + idx) for idx in range(len(list_option_name))]\n",
    "    list_option_idx_name = [ [option_idx, option_name] for option_idx, option_name in zip(list_option_idx, list_option_name)]\n",
    "    list_option_idx_name = sorted(list_option_idx_name, key=lambda x: len(x[1]), reverse=True)\n",
    "    list_option_match = []\n",
    "    # search option_idx and option_name\n",
    "    for option_idx, option_name in list_option_idx_name:\n",
    "        if option_idx in result_pred or option_name in result_pred:\n",
    "            list_option_match.append(option_idx)\n",
    "            if option_name in result_pred:\n",
    "                result_pred = result_pred.replace(option_name, '')\n",
    "    if len(list_option_match)==1:\n",
    "        return list_option_match[0]\n",
    "    elif len(list_option_match)>1:\n",
    "        return None\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 494/494 [00:00<00:00, 98877.89it/s]\n"
     ]
    }
   ],
   "source": [
    "list_dict_result_correct, list_dict_result_wrong, list_dict_result_none = [], [], []\n",
    "for idx, dict_test in enumerate(tqdm(list_dict_test)):\n",
    "    list_option_name = [dict_test['A'], dict_test['B'], dict_test['C'], dict_test['D'], dict_test['E']]\n",
    "    dict_test['Prediction'] = get_prediction(dict_test['Result'], list_option_name)\n",
    "    if not dict_test['Prediction']:\n",
    "        list_dict_result_none.append(dict_test)\n",
    "    elif dict_test['Answer'] == dict_test['Prediction']:\n",
    "        list_dict_result_correct.append(dict_test)\n",
    "    else:\n",
    "        list_dict_result_wrong.append(dict_test)\n",
    "    # if len(dict_test['Result']) > 6:\n",
    "    #     print(dict_test['Result']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 50.0% with 247 correct, 241 wrong, and 6 none\n"
     ]
    }
   ],
   "source": [
    "count_correct = len(list_dict_result_correct)\n",
    "count_wrong = len(list_dict_result_wrong)\n",
    "count_none = len(list_dict_result_none)\n",
    "acc = round(len(list_dict_result_correct) / len(list_dict_test)*100, 2)\n",
    "print(f\"Accuracy is {acc}% with {count_correct} correct, {count_wrong} wrong, and {count_none} none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Too long 111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../log/{name_task}_0_494.json', 'w', encoding=\"utf-8\") as f:\n",
    "    f.write(json.dumps(list_dict_test, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494 181 313\n"
     ]
    }
   ],
   "source": [
    "with open(f'../log/{name_task}_0_494.json', 'r', encoding=\"utf-8\") as f:\n",
    "    list_dict_test_sample = json.load(f)\n",
    "with open('../data/list_test_knowledge_idx.txt', 'r') as f:\n",
    "    list_test_knowledge_idx = f.readlines()\n",
    "with open('../data/list_test_example_idx.txt', 'r') as f:\n",
    "    list_test_example_idx = f.readlines()\n",
    "list_test_knowledge_idx = [ int(idx.strip()) for idx in list_test_knowledge_idx if idx.strip() ]\n",
    "list_test_example_idx = [ int(idx.strip()) for idx in list_test_example_idx if idx.strip() ]\n",
    "list_dict_test_knowledge = [ list_dict_test_sample[idx] for idx in list_test_knowledge_idx ]\n",
    "list_dict_test_example = [ list_dict_test_sample[idx] for idx in list_test_example_idx ]\n",
    "print(len(list_dict_test_sample), len(list_dict_test_knowledge), len(list_dict_test_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_performance(list_dict_test_sample):\n",
    "    list_dict_result_correct, list_dict_result_wrong, list_dict_result_none = [], [], []\n",
    "    for idx, dict_test in enumerate(list_dict_test_sample):\n",
    "        if not dict_test['Prediction']:\n",
    "            list_dict_result_none.append(dict_test)\n",
    "        elif dict_test['Answer'] == dict_test['Prediction']:\n",
    "            list_dict_result_correct.append(dict_test)\n",
    "        else:\n",
    "            list_dict_result_wrong.append(dict_test)\n",
    "    count_correct = len(list_dict_result_correct)\n",
    "    count_wrong = len(list_dict_result_wrong)\n",
    "    count_none = len(list_dict_result_none)\n",
    "    acc = len(list_dict_result_correct) / len(list_dict_test_sample)\n",
    "    print(f\"Accuracy is {round(acc*100, 2)}% with {count_none} none, {count_correct} correct, and {count_wrong} wrong， total {len(list_dict_test_sample)}\")\n",
    "    return round(acc, 4), count_none, count_correct, count_wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 49.17% with 0 none, 89 correct, and 92 wrong， total 181\n",
      "Accuracy is 52.08% with 0 none, 163 correct, and 150 wrong， total 313\n",
      "Accuracy is 51.01% with 0 none, 252 correct, and 242 wrong， total 494\n"
     ]
    }
   ],
   "source": [
    "acc_MK, count_none_MK, _, _ = cal_performance(list_dict_test_knowledge)\n",
    "acc_CA, count_none_CA, _, _ = cal_performance(list_dict_test_example)\n",
    "acc_all, count_none_all, _, _ = cal_performance(list_dict_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t0.4917\t0\t0.5208\t0\t0.5101\n"
     ]
    }
   ],
   "source": [
    "print(count_none_MK, acc_MK, count_none_CA, acc_CA, count_none_all, acc_all, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494 query and Cost: 1.32 RMB\n"
     ]
    }
   ],
   "source": [
    "sum_tokens_all = sum([ dict_test['usage']['total_tokens'] for dict_test in list_dict_test])\n",
    "cost = sum_tokens_all / 1000 * 0.002 * 6.9348\n",
    "print(f\"{len(list_dict_test)} query and Cost: {cost:.2f} RMB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92773, 187.7995951417004, 2749, 5.564777327935222)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_tokens_prompt = sum([ dict_test['usage']['prompt_tokens'] for dict_test in list_dict_test])\n",
    "sum_tokens_completion = sum([ dict_test['usage']['completion_tokens'] for dict_test in list_dict_test])\n",
    "sum_tokens_prompt, sum_tokens_prompt/494, sum_tokens_completion, sum_tokens_completion/494"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0dda50c8f3106409627f3c7388c0a3de156665d66c9593dafc60667d2d1be47"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
